<Q_TABLE: test_alpha_06.json, ANGLE_SAMPLES: 40, SPEED_SAMPLES: 39, ACTION_NUM: 80, EPISODES: 500000, START_BASE: (600, 300), START_BOX: (600, 500), LEARNING_RATE: 0.7, DISCOUNT: 0.98, MAX_EPSILON: 1.0, MIN_EPSILON: 0.05, DECAY_RATE: 0.005, REWARD_ALPHA: 0.6, REWARD_BETA: 0.4>
<Q_TABLE: test_learning_06.json, ANGLE_SAMPLES: 40, SPEED_SAMPLES: 39, ACTION_NUM: 80, EPISODES: 500000, START_BASE: (600, 300), START_BOX: (600, 500), LEARNING_RATE: 0.6, DISCOUNT: 0.98, MAX_EPSILON: 1.0, MIN_EPSILON: 0.05, DECAY_RATE: 0.005, REWARD_ALPHA: 0.6, REWARD_BETA: 0.4>
<Q_TABLE: 40_54_2_80.json, ANGLE_SAMPLES: 40, SPEED_SAMPLES: 54, ACTION_NUM: 80, EPISODES: 200000, START_BASE: (600, 300), START_BOX: (600, 500), LEARNING_RATE: 0.2, DISCOUNT: 0.98, MAX_EPSILON: 1.0, MIN_EPSILON: 0.05, DECAY_RATE: 0.005, REWARD_ALPHA: 0.8, REWARD_BETA: 0.2>
<Q_TABLE: 40_54_2_80.json, ANGLE_SAMPLES: 40, SPEED_SAMPLES: 54, ACTION_NUM: 80, EPISODES: 200000, START_BASE: (600, 300), START_BOX: (600, 500), LEARNING_RATE: 0.2, DISCOUNT: 0.98, MAX_EPSILON: 1.0, MIN_EPSILON: 0.05, DECAY_RATE: 0.005, REWARD_ALPHA: 0.7, REWARD_BETA: 0.3>
<Q_TABLE: 40_54_2_80.json, ANGLE_SAMPLES: 40, SPEED_SAMPLES: 54, ACTION_NUM: 80, EPISODES: 200000, START_BASE: (600, 300), START_BOX: (600, 500), LEARNING_RATE: 0.2, DISCOUNT: 0.98, MAX_EPSILON: 1.0, MIN_EPSILON: 0.05, DECAY_RATE: 0.005, REWARD_ALPHA: 0.7, REWARD_BETA: 0.3>
<Q_TABLE: 40_54_2_80.json, ANGLE_SAMPLES: 40, SPEED_SAMPLES: 54, ACTION_NUM: 80, EPISODES: 200000, START_BASE: (600, 300), START_BOX: (600, 500), LEARNING_RATE: 0.2, DISCOUNT: 0.98, MAX_EPSILON: 1.0, MIN_EPSILON: 0.05, DECAY_RATE: 0.005, REWARD_ALPHA: 0.7, REWARD_BETA: 0.3>
<Q_TABLE: 40_54_2_80.json, ANGLE_SAMPLES: 40, SPEED_SAMPLES: 54, ACTION_NUM: 80, EPISODES: 200000, START_BASE: (600, 300), START_BOX: (600, 500), LEARNING_RATE: 0.2, DISCOUNT: 0.98, MAX_EPSILON: 1.0, MIN_EPSILON: 0.05, DECAY_RATE: 0.005, REWARD_ALPHA: 0.7, REWARD_BETA: 0.3>
<Q_TABLE: 40_54_2_80.json, ANGLE_SAMPLES: 40, SPEED_SAMPLES: 54, ACTION_NUM: 80, EPISODES: 200000, START_BASE: (600, 300), START_BOX: (600, 500), LEARNING_RATE: 0.2, DISCOUNT: 0.98, MAX_EPSILON: 1.0, MIN_EPSILON: 0.05, DECAY_RATE: 0.005, REWARD_ALPHA: 0.7, REWARD_BETA: 0.3>
<Q_TABLE: 40_54_2_80.json, ANGLE_SAMPLES: 40, SPEED_SAMPLES: 54, ACTION_NUM: 80, EPISODES: 200000, START_BASE: (600, 300), START_BOX: (600, 500), LEARNING_RATE: 0.2, DISCOUNT: 0.98, MAX_EPSILON: 1.0, MIN_EPSILON: 0.05, DECAY_RATE: 0.005, REWARD_ALPHA: 0.7, REWARD_BETA: 0.3>
<Q_TABLE: 40_54_2_80.json, ANGLE_SAMPLES: 40, SPEED_SAMPLES: 54, ACTION_NUM: 80, EPISODES: 200000, START_BASE: (600, 300), START_BOX: (600, 500), LEARNING_RATE: 0.2, DISCOUNT: 0.98, MAX_EPSILON: 1.0, MIN_EPSILON: 0.05, DECAY_RATE: 0.005, REWARD_ALPHA: 0.7, REWARD_BETA: 0.3>
<Q_TABLE: 40_54_2_80.json, ANGLE_SAMPLES: 40, SPEED_SAMPLES: 54, ACTION_NUM: 80, EPISODES: 200000, START_BASE: (600, 300), START_BOX: (600, 500), LEARNING_RATE: 0.2, DISCOUNT: 0.98, MAX_EPSILON: 1.0, MIN_EPSILON: 0.05, DECAY_RATE: 0.005, REWARD_ALPHA: 0.7, REWARD_BETA: 0.3>
<Q_TABLE: up_pend.json, ANGLE_SAMPLES: 40, SPEED_SAMPLES: 54, ACTION_NUM: 80, EPISODES: 200000, START_BASE: (600, 300), START_BOX: (580, 100), LEARNING_RATE: 0.7, DISCOUNT: 0.95, MAX_EPSILON: 1.0, MIN_EPSILON: 0.05, DECAY_RATE: 0.005, REWARD_ALPHA: 0.7, REWARD_BETA: 0.3>
<Q_TABLE: 40_54_2_80.json, ANGLE_SAMPLES: 40, SPEED_SAMPLES: 90, ACTION_NUM: 80, EPISODES: 200000, START_BASE: (600, 300), START_BOX: (600, 500), LEARNING_RATE: 0.7, DISCOUNT: 0.95, MAX_EPSILON: 1.0, MIN_EPSILON: 0.05, DECAY_RATE: 0.005, REWARD_ALPHA: 0.7, REWARD_BETA: 0.3>
<Q_TABLE: 40_90_2_80.json, ANGLE_SAMPLES: 40, SPEED_SAMPLES: 90, ACTION_NUM: 80, EPISODES: 200000, START_BASE: (600, 300), START_BOX: (600, 500), LEARNING_RATE: 0.7, DISCOUNT: 0.95, MAX_EPSILON: 1.0, MIN_EPSILON: 0.05, DECAY_RATE: 0.005, REWARD_ALPHA: 0.7, REWARD_BETA: 0.3>
<Q_TABLE: 40_90_2_80.json, ANGLE_SAMPLES: 40, SPEED_SAMPLES: 90, ACTION_NUM: 80, EPISODES: 200000, START_BASE: (600, 300), START_BOX: (600, 500), LEARNING_RATE: 0.2, DISCOUNT: 0.98, MAX_EPSILON: 1.0, MIN_EPSILON: 0.05, DECAY_RATE: 0.005, REWARD_ALPHA: 0.7, REWARD_BETA: 0.3>
<Q_TABLE: 40_90_2_80.json, ANGLE_SAMPLES: 40, SPEED_SAMPLES: 90, ACTION_NUM: 80, EPISODES: 200000, START_BASE: (600, 300), START_BOX: (600, 500), LEARNING_RATE: 0.2, DISCOUNT: 0.98, MAX_EPSILON: 1.0, MIN_EPSILON: 0.05, DECAY_RATE: 0.005, REWARD_ALPHA: 0.7, REWARD_BETA: 0.3>
<Q_TABLE: 40_90_2_80_2.json, ANGLE_SAMPLES: 40, SPEED_SAMPLES: 90, ACTION_NUM: 80, EPISODES: 200000, START_BASE: (600, 300), START_BOX: (600, 500), LEARNING_RATE: 0.2, DISCOUNT: 0.98, MAX_EPSILON: 1.0, MIN_EPSILON: 0.05, DECAY_RATE: 0.005, REWARD_ALPHA: 0.6, REWARD_BETA: 0.4>
<Q_TABLE: 40_90_2_80.json, ANGLE_SAMPLES: 40, SPEED_SAMPLES: 90, ACTION_NUM: 80, EPISODES: 200000, START_BASE: (600, 300), START_BOX: (600, 500), LEARNING_RATE: 0.2, DISCOUNT: 0.98, MAX_EPSILON: 1.0, MIN_EPSILON: 0.05, DECAY_RATE: 0.005, REWARD_ALPHA: 0.6, REWARD_BETA: 0.4>
<Q_TABLE: 40_90_2_80_3.json, ANGLE_SAMPLES: 40, SPEED_SAMPLES: 90, ACTION_NUM: 80, EPISODES: 500000, START_BASE: (600, 300), START_BOX: (600, 500), LEARNING_RATE: 0.2, DISCOUNT: 0.98, MAX_EPSILON: 1.0, MIN_EPSILON: 0.05, DECAY_RATE: 0.005, REWARD_ALPHA: 0.7, REWARD_BETA: 0.3, SUCCESS_RATE: 0.018736>
<Q_TABLE: new_reward.json, ANGLE_SAMPLES: 40, SPEED_SAMPLES: 90, ACTION_NUM: 80, EPISODES: 500000, START_BASE: (600, 300), START_BOX: (600, 500), LEARNING_RATE: 0.2, DISCOUNT: 0.98, MAX_EPSILON: 1.0, MIN_EPSILON: 0.05, DECAY_RATE: 0.005, REWARD_ALPHA: 0.6, REWARD_BETA: 0.4, SUCCESS_RATE: 0.01317>
<Q_TABLE: new_reward.json, ANGLE_SAMPLES: 40, SPEED_SAMPLES: 90, ACTION_NUM: 80, EPISODES: 1000000, START_BASE: (600, 300), START_BOX: (600, 500), LEARNING_RATE: 0.2, DISCOUNT: 0.98, MAX_EPSILON: 1.0, MIN_EPSILON: 0.05, DECAY_RATE: 0.005, REWARD_ALPHA: 0.6, REWARD_BETA: 0.4>
<Q_TABLE: new_reward.json, ANGLE_SAMPLES: 40, SPEED_SAMPLES: 90, ACTION_NUM: 80, EPISODES: 1000000, START_BASE: (600, 300), START_BOX: (600, 500), LEARNING_RATE: 0.5, DISCOUNT: 0.98, MAX_EPSILON: 1.0, MIN_EPSILON: 0.05, DECAY_RATE: 0.005, REWARD_ALPHA: 0.6, REWARD_BETA: 0.4>
<Q_TABLE: almost_perfect.json, ANGLE_SAMPLES: 40, SPEED_SAMPLES: 90, ACTION_NUM: 80, EPISODES: 1000000, START_BASE: (600, 300), START_BOX: (600, 500), LEARNING_RATE: 0.5, DISCOUNT: 0.98, MAX_EPSILON: 1.0, MIN_EPSILON: 0.05, DECAY_RATE: 0.005, REWARD_ALPHA: 0.6, REWARD_BETA: 0.4>
<Q_TABLE: new_reward.json, ANGLE_SAMPLES: 40, SPEED_SAMPLES: 90, ACTION_NUM: 80, EPISODES: 1000000, START_BASE: (600, 300), START_BOX: (600, 500), LEARNING_RATE: 0.2, DISCOUNT: 0.98, MAX_EPSILON: 1.0, MIN_EPSILON: 0.05, DECAY_RATE: 0.005, REWARD_ALPHA: 0.6, REWARD_BETA: 0.4>
<Q_TABLE: new_reward_learning05.json, ANGLE_SAMPLES: 40, SPEED_SAMPLES: 90, ACTION_NUM: 80, EPISODES: 1000000, START_BASE: (600, 300), START_BOX: (600, 500), LEARNING_RATE: 0.5, DISCOUNT: 0.98, MAX_EPSILON: 1.0, MIN_EPSILON: 0.05, DECAY_RATE: 0.005, REWARD_ALPHA: 0.6, REWARD_BETA: 0.4>
